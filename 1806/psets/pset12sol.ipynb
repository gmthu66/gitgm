{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 pset 12 - SOLUTIONS\n",
    "\n",
    "Due Wednesday, November 28 at 10:55am."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (10+10+10 points)\n",
    "\n",
    "Suppose that $A$ is a real $3\\times 2$ matrix.\n",
    "\n",
    "**(a)** If you solve the ODE $\\frac{dx}{dt} = -A^T A x$ for some initial condition $x(0)$, then which of the following are *possible* behaviors for $x(t)$?\n",
    "\n",
    "* $x(t)$ is a nonzero constant vector.\n",
    "* $x(t)$ monotonically approaches a nonzero constant vector as $t \\to \\infty$.\n",
    "* $x(t)$ monononically decays to the zero vector.\n",
    "* $\\Vert x(t) \\Vert$ diverges as $t \\to \\infty$.\n",
    "* $x(t)$ oscillates.\n",
    "* $x(t)$ has decaying oscillations that approach a nonzero constant vector (like problem 1 of pset 11).\n",
    "* $x(t)$ jumps around discontinuously and eventually eats all of your turkey.\n",
    "\n",
    "**(b)** For each of the *possible* behaviors you indicated in part (a), give a matrix $A$ and a corresponding initial condition $x(0)$ which will lead to that behavior.\n",
    "\n",
    "**(c)** For each of the matrices you gave in part (b), compute the singular value decomposition: give the singular values $\\sigma$ and the corresponding left and right singular vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution \n",
    "\n",
    "**(a)** The first three options are all possible, as we show in the next part, while the rest are impossible. \n",
    "\n",
    "Since $-A^TA$ is a symmetric matrix, it will have real eigenvalues and so oscillating solutions will never occur. \n",
    "\n",
    "To see why $\\Vert x(t) \\Vert$ cannot diverge as $t \\to \\infty$, we note that $A^T A$ will in general be positive semidefinite (positive definite if $A$ has full column rank), and $-A^T A$ is **negative semidefinite**. This means that the eigenvalues of $-A^TA$ are â‰¤ 0, and so the solutions $x(t)$ must either decay to zero or approach a nonzero constant vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** $A^TA$ is a $2\\times 2$ matrix with eigenvalues $\\lambda_1, \\lambda_2 \\geq 0 $. Therefore the general solution of $\\frac{dx}{dt} = -A^T A x$ will be of the form:\n",
    "$$x(t) = c_1 e^{-\\lambda_1 t} v_1 + c_2 e^{-\\lambda_2 t} v_2,$$\n",
    "where $v_1$ and $v_2$ are the corresponding eigenvectors of $A^TA$. \n",
    "\n",
    "* One way in which $x(t)$ may be a constant vector is if $\\lambda_1=\\lambda_2 = 0$. However, since $A^TA$ is symmetric, this would require that $A = 0$. To find a non trivial example, let us choose $A$ as a rank 1 matrix, e.g.\n",
    "\\begin{align}\n",
    "A = \\begin{pmatrix} 1 & -2 \\\\ 0 & 0 \\\\ -1 & 2 \\end{pmatrix}, \\implies B = A^TA = \\begin{pmatrix} 2 & -4 \\\\ -4 & 8 \\end{pmatrix}\n",
    "\\end{align}\n",
    "Then $B$ has eigenvalues $\\lambda_1 = 0$ and $\\lambda_2 = 10$, with eigenvectors $v_1 = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$ and $v_2 = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}$ (note that they are orthogonal!). So if we have an initial condition $x(0)$ which is parallel to $v_1$, then $x(t)$ will remain constant for all time.\n",
    "\n",
    "* We can use the same matrix $A$ as in the previous example, but now choose an $x(0)$ that is **not** parallel to $v_1$. Then $x(t)$ monotonically approaches $v_1$ as $t \\to \\infty$, since the part of the solution corresponding to $\\lambda_2 = 10$ decays.\n",
    "\n",
    "* In order for $x(t)$ to monotonically decay to the zero vector, one option is to use the matrix from above but choose an $x(0)$ that is parallel to $v_2$.   For it to decay for *any* initial condition, on the other hand, we need $\\lambda_1, \\lambda_2 > 0$; to get this, we would choose an $A$ with full column rank, e.g. \n",
    "\\begin{align}\n",
    "A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ -1 & 0 \\end{pmatrix}, \\implies B = A^TA = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "Then $B$ has eigenvalues $\\lambda_1 = 2$ and $\\lambda_2 = 1$, which are real and strictly positive, and so $x(t)$ monotonically decays to the zero vector as $t\\to\\infty$ for *any* initial vector $x(0)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** \n",
    "* Consider the matrix\n",
    "\\begin{align}\n",
    "A &= \\begin{pmatrix} 1 & -2 \\\\ 0 & 0 \\\\ -1 & 2 \\end{pmatrix}\\\\\n",
    "\\implies A^T A = \\begin{pmatrix} 2 & -4 \\\\ -4 & 8 \\end{pmatrix}, &\\;\\; AA^T = \\begin{pmatrix} 5 & 0 & -5 \\\\ 0 & 0 & 0 \\\\ -5 & 0 & 5 \\end{pmatrix}\n",
    "\\end{align}\n",
    "The eigenvalues of $A^T A$ are $0$ and $10$ and so there is only one nonzero singular value $\\sigma_1 = \\sqrt{10}$. The right singular vector can be found from the eigenvector of $A^TA$ for $\\lambda = 10$, which is (including normalization):\n",
    "\\begin{align}\n",
    "v_1 = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}\n",
    "\\end{align}\n",
    "The left singular vector can then be obtained using the relationsip that $Av = \\sigma u$, so that\n",
    "\\begin{align}\n",
    "u_1 = Av_1/\\sigma_1 = \\frac{1}{\\sqrt{50}}\\begin{pmatrix} 1 & -2 \\\\ 0 & 0 \\\\ -1 & 2 \\end{pmatrix}\\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} -1 \\\\0\\\\ 1 \\end{pmatrix} \n",
    "\\end{align}\n",
    "\n",
    "* Now consider the matrix \n",
    "\\begin{align}\n",
    "A &= \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ -1 & 0 \\end{pmatrix}\\\\\n",
    "\\implies A^T A = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}, &\\;\\; AA^T = \\begin{pmatrix} 1 & 0 & -1 \\\\ 0 & 1 & 0 \\\\ -1 & 0 & 1 \\end{pmatrix}\n",
    "\\end{align}\n",
    "The eigenvalues of $A^T A$ are $1$ and $2$ and so there are two singular values $\\sigma_1 = 1$ and $\\sigma_2 = \\sqrt{2}$. The right singular vectors are the corresponding eigenvectors of $A^T A$: \n",
    "\\begin{align}\n",
    "v_1 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\;\\; \\text{and} \\;\\; v_2 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n",
    "\\end{align}\n",
    "The left singular vectors are then  obtained using the relationsip that $Av = \\sigma u$, so that:\n",
    "\\begin{align}\n",
    "u_1 &=  Av_1/\\sigma_1 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ -1 & 0 \\end{pmatrix}\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\\\\\n",
    "\\;\\; \\text{and} \\;\\; u_2 &= Av_2/\\sigma_2 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ -1 & 0 \\end{pmatrix}\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (20 points)\n",
    "\n",
    "In class and in the textbook, positive-definiteness was defined only for Hermitian matrices. However, it can be extended to arbitrary square matrices as follows:\n",
    "\n",
    "* The matrix $A$ is positive-definite if $A + A^H$ is positive-definite (in the sense defined in class and in the book: $A + A^H$ has positive eigenvalues, or equivalently $x^H(A+A^H)x >0$ for all $x \\ne 0$, or equivalently $A^H + A = B^H B$ where $B$ has full column rank).\n",
    "\n",
    "Show that if $A + A^H$ is positive definite, then the eigenvalues of $A$ have **positive real parts**.\n",
    "\n",
    "(Hint: consider an eigenvector $Ax = \\lambda x$.  How can you use this in one of the positive-definite conditions for $A+A^H$ above?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Suppose that $A + A^H$ is positive definite (in the usual 18.06 sense from the textbook: it is Hermitian with all negative eigenvalues etc.). Consider an eigenvalue of $A$ so that $$Ax = \\lambda x.$$ Taking the Hermitian adjoint of both sides of this equation implies that $x^HA^H = \\bar{\\lambda} x^H$. Multipling both sides on the right by $x$ then tells us that\n",
    "$$ \\boxed{x^HA^Hx = \\bar{\\lambda} x^H x} \\,.$$\n",
    "We can also multiply the original eigenvalue equation on the left by $x^H$, which tells us that\n",
    "$$ \\boxed{x^HAx = \\lambda x^H x} \\,.$$\n",
    "We can then add these two equations:\n",
    "\\begin{align}\n",
    "x^HAx + x^HA^Hx = x^H(A+A^H)x &> 0\\\\\n",
    "\\implies \\lambda x^H x + \\bar{\\lambda} x^H x &> 0 \\\\\n",
    "\\implies (\\lambda + \\bar{\\lambda}) x^H x &> 0 \n",
    "\\end{align}\n",
    "But since $x^H x =\\Vert x \\Vert^2 > 0$, this means that $(\\lambda + \\bar{\\lambda}) = 2\\,\\mbox{Re}(\\lambda) > 0$. Thus the eigenvalues of $A$ must have positive real parts. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
