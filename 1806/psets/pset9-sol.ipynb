{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.06 pset 9 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (10 points)\n",
    "\n",
    "The trace of an $m\\times m$ matrix $A$ is the sum of the diagonal elements:\n",
    "$$\n",
    "\\operatorname{trace} A = \\sum_{i=1}^m a_{ii}\n",
    "$$\n",
    "where $a_{ij}$ is the entry in the i-th row and j-th column of $A$.\n",
    "\n",
    "In class, I claimed that $\\operatorname{trace}(AB) = \\operatorname{trace}(BA)$.  Show this, using the formula $\\sum_{k=1}^m a_{ik} b_{kj}$ for the (i,j) entry of $AB$ from lecture 2.  (You should be able to see a similar formula for the entries of BA.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Given a matrix $M$, let $M_{ij}$ denote the row-$i$ column-$j$ entry of $M$.  Let $a_{ij} = A_{ij}$ and $b_{ij} = B_{ij}$ as suggested in the problem statement.\n",
    "\n",
    "By the definition of trace and the formula for a matrix entry of a matrix product, we have $$\\text{trace}(AB) = \\sum_{i = 1}^m (AB)_{ii} = \\sum_{i = 1}^m \\sum_{k = 1}^m a_{ik}b_{ki}.$$  Similarly, we have $$\\text{trace}(BA) = \\sum_{i = 1}^m \\sum_{k = 1}^m b_{ik}a_{ki}.$$  But as $b_{ik}a_{ki} = a_{ki}b_{ik}$ ($a_{ki}$ and $b_{ik}$ are *scalars*), we can see by just exchanging the names of the indexing variables $i$ and $k$ in the sum formula for $\\text{trace}(BA)$ that the two sums above are equal, so $\\text{trace}(AB) = \\text{trace}(BA)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (3+5+3+5+3+5 points)\n",
    "\n",
    "(Based on Strang, section 6.2, problem 9.)\n",
    "\n",
    "Suppose we form the sequence\n",
    "\n",
    "$$\n",
    "g_0,g_1,g_2,g_3,\\ldots = 0, 1, \\frac{1}{2}, \\frac{3}{4}, \\frac{5}{8}, \\frac{11}{16}, \\frac{21}{32}, \\frac{43}{64}, \\frac{85}{128}, \\frac{171}{256}, \\frac{341}{512}, \\frac{683}{1024}, \\frac{1365}{2048}, \\frac{2731}{4096}, \\frac{5461}{8192}, \\frac{10923}{16384}, \\frac{21845}{32768}, \\ldots\n",
    "$$\n",
    "\n",
    "by the rule that $g_{k+2} = \\frac{g_{k+1} + g_k}{2}$: each number is the *average of the previous two*.\n",
    "\n",
    "**(a)** If we define $x_k = \\begin{pmatrix} g_{k+1} \\\\ g_k \\end{pmatrix}$, then write the rule for the sequence in matrix form: $x_{k+1} = A x_k$.  What is $A$?\n",
    "\n",
    "**(b)** Find the eigenvalues and eigenvectors of A.\n",
    "\n",
    "**(c)** The eigenvalues immediately tell which of these three possibilities: the sequence *blows up*, *decays*, or *goes to a constant* as $n\\to\\infty$?    Does this behavior depend on the starting vector $x_0$?\n",
    "\n",
    "**(d)** Find the limit as $n\\to\\infty$ of $A^n$ from the diagonalization of $A$.\n",
    "\n",
    "**(e)** If $g_0 = 0$ and $g_1 = 1$, i.e. $x_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, then show that the sequence approaches 2/3.\n",
    "\n",
    "**(f)** With $g_0 = 0$ and $g_1 = 1$ as in the previous part, how fast does $g_n - 2/3$ go to zero?  In particular, what should $\\frac{g_{n+1} - 2/3}{g_n - 2/3}$ approach for large $n$?   Check your answer by the using the following Julia code, which numerically computes the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "**(a)**  By definition of the $x$'s and the $g's$, we have $$x_{k + 1} = \\begin{pmatrix} g_{k+2} \\\\ g_{k+1} \\end{pmatrix} = \\begin{pmatrix} (1/2)g_k + (1/2)g_{k + 1} \\\\ g_{k + 1}\\end{pmatrix} = \\begin{pmatrix} 1/2 & 1/2 \\\\ 1 & 0\\end{pmatrix}\\begin{pmatrix} g_{k + 1} \\\\ g_k\\end{pmatrix} = \\begin{pmatrix} 1/2 & 1/2 \\\\ 1 & 0\\end{pmatrix}x_k$$ so the matrix we're looking for is $$\\boxed{A = \\begin{pmatrix} 1/2 & 1/2 \\\\ 1 & 0\\end{pmatrix}.}$$\n",
    "\n",
    "**(b)**  The characteristic polynomial of $A$ is $$p_A(\\lambda) = \\det(A - \\lambda I) = \\det\\begin{pmatrix}1/2 - \\lambda & 1/2 \\\\ 1 & - \\lambda\\end{pmatrix} = \\lambda^2 - (1/2)\\lambda - 1/2 = (\\lambda - 1)(\\lambda + 1/2).$$  Setting equal to zero, we see that the eigenvalues are $\\boxed{\\lambda = 1}$ and $\\boxed{\\lambda = -1/2}$. To find the eigenvectors $(x, y)$ with eigenvalue 1, we need to solve the equation $$\\begin{pmatrix}1/2 - \\lambda & 1/2 \\\\ 1 & - \\lambda\\end{pmatrix}\\begin{pmatrix}x\\\\ y \\end{pmatrix} = \\begin{pmatrix}(x + y)/2\\\\ x \\end{pmatrix}= \\begin{pmatrix}x\\\\ y \\end{pmatrix}.$$  The equation in the second coordinate says $x = y$, and as this matrix equation is nonzero and singular its full solution set is therefore spanned by $(1, 1)$.  So $$\\boxed{\\text{the eigenvectors of } A \\text{ with eigenvalue 1 are all nonzero multiples of } (1, 1).}$$  To find the eigenvectors with eigenvalue $-1/2$, we need to solve the equation $$\\begin{pmatrix}1/2 - \\lambda & 1/2 \\\\ 1 & - \\lambda\\end{pmatrix}\\begin{pmatrix}x\\\\ y \\end{pmatrix} = \\begin{pmatrix}(x + y)/2\\\\ x \\end{pmatrix}= \\begin{pmatrix}-x/2\\\\ -y/2 \\end{pmatrix}.$$  For the same reasons (a nonzero singular 2 by 2 system), we can read off the solutions from the equation in the second (or first) coordinate: $$\\boxed{\\text{the eigenvectors of } A \\text{ with eigenvalue -1/2 are all nonzero multiples of } (1, -2) }$$\n",
    "\n",
    "**(c)**  The eigenvalue of $\\lambda=-1/2$ has $|\\lambda|<1$, so it gives a term that decays to zero, and the eigenvalue of $1$ gives a \"steady state\" term that goes to a constant, when we compute $A^n x_0$ for $n \\to \\infty$.   The only thing that depends on $x_0$ is *which* constant vector we get in the limit.\n",
    "\n",
    "More explicitly, take the basis $\\{v_1, v_{-1/2}\\}$ for $\\mathbb{R}^2$ with $v_1 = (1, 1)$ and $v_{-1/2} = (1, -2)$.  It consists of eigenvectors of $A$ and $v_1$ has eigenvalue 1 and $v_{-1/2}$ has eigenvalue $-1/2$.  Since it's a basis, any vector $x \\in \\mathbb{R}^2$ can be written $x = c_1v_1 + c_{-1/2}v_{-1/2}$ for some unique scalars $c_1$ and $c_{-1/2}$.  For any power $n$, we have $$A^nx = A^n(c_1v_1 + c_{-1/2}v_{-1/2} = c_1A^nv_1 + c_{-1/2}A^nv_{-1/2} = c_1v_1 + (-1/2)^nc_{-1/2}v_{-1/2}.$$  As $n \\rightarrow \\infty$, the limit is $c_1v_1$, so for very large $n$ the matrix $A^n$ is almost projection to the line spanned by $v_1$ in the $v_1, v_{-1/2}$ coordinates (this is *not* orthogonal projection because $v_1$ and $v_{-1/2}$ aren't orthogonal!).  In particular, $$\\boxed{\\text{no matter what vector } x \\text{ we start with the limit} \\lim_{n \\rightarrow \\infty} A^nx \\text{ exists and goes to a constant.}}$$  Notice that this constant will be zero exactly when the coefficient $c_1$ was zero, i.e. when $x$ was on the line spanned by $v_{-1/2}$ - in this case you could say it decays if you like.\n",
    "\n",
    "**(d)**  Let $v_1, v_{-1/2}$ be as in the previous part and let $$X = (v_1 | v_{-1/2}) = \\begin{pmatrix}1 & 1 \\\\ 1 & -2\\end{pmatrix}.$$  Then the diagonalization of $A$ is $$A = X\\Lambda X^{-1}$$ where $$\\Lambda = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1/2\\end{pmatrix}.$$ Therefore for any integer $n$ we have $$A^n = (X\\Lambda X^{-1})^n = X\\Lambda^nX^{-1} = X\\begin{pmatrix} 1^n & 0 \\\\ 0 & (-1/2)^n\\end{pmatrix}X^{-1}$$ and so $$\\lim_{n \\rightarrow \\infty} A^n = X\\begin{pmatrix}1 & 0 \\\\ 0 & 0\\end{pmatrix}X^{-1} = \\begin{pmatrix}1 & 1 \\\\ 1 & -2\\end{pmatrix}\\begin{pmatrix}1 & 0 \\\\ 0 & 0\\end{pmatrix}\\frac{-1}{3}\\begin{pmatrix}-2 & -1 \\\\ -1 & 1\\end{pmatrix} = \\boxed{\\begin{pmatrix} 2/3 & 1/3 \\\\ 2/3 & 1/3\\end{pmatrix}}.$$  As a sanity check, remember from the argument in part (c) that this matrix should be the non-orthogonal projetion to the line spanned by $(1, 1)$ with nullspace given by the line spanned by $(1, -2)$.  You can see that this matrix fixes the vector (1, 1) and kills the vector $(1, -2)$, so we did it right.\n",
    "\n",
    "**(e)**  We can just use part (d): $$\\lim_{n \\rightarrow \\infty} A^nx_0 = (\\lim_{n \\rightarrow \\infty} A^n)x_0 = \\begin{pmatrix} 2/3 & 1/3 \\\\ 2/3 & 1/3\\end{pmatrix}\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2/3 \\\\ 2/3 \\end{pmatrix}$$ which means that the sequence $\\begin{pmatrix} g_n \\\\ g_{n + 1} \\end{pmatrix}$ goes to $2/3$, as needed.\n",
    "\n",
    "Equivalently, if we expand $x_0$ in the basis of the eigenvectors, we get:\n",
    "$$\n",
    "x_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\frac{2}{3} v_1 + \\frac{1}{3} v_{-1/2} = \\frac{2}{3} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} + \\frac{1}{3} \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}\n",
    "$$\n",
    "Hence\n",
    "$$\n",
    "x_n = \\begin{pmatrix} g_{n+1} \\\\ g_n \\end{pmatrix} = A^n x_0 = \\frac{2}{3} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} + \\frac{1}{3} \\left( -\\frac{1}{2} \\right)^n \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} \\to \\frac{2}{3} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n",
    "$$\n",
    "since the second eigenvector gets multiplied by $(-1/2)^n \\to 0$, and we again get the limit $g_n \\to 2/3$.    (If we hadn't already done part d, this approach would have been a bit easier.)\n",
    "\n",
    "It is easy to see from the numerical values of the sequence, below, that this is in fact what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Array{Float64,1}:\n",
       " 0.0     \n",
       " 1.0     \n",
       " 0.5     \n",
       " 0.75    \n",
       " 0.625   \n",
       " 0.6875  \n",
       " 0.65625 \n",
       " 0.671875\n",
       " 0.664063\n",
       " 0.667969\n",
       " 0.666016\n",
       " 0.666992\n",
       " 0.666504\n",
       " 0.666748\n",
       " 0.666626\n",
       " 0.666687\n",
       " 0.666656\n",
       " 0.666672\n",
       " 0.666664\n",
       " 0.666668\n",
       " 0.666666\n",
       " 0.666667\n",
       " 0.666667\n",
       " 0.666667\n",
       " 0.666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gsequence(n)\n",
    "    g = [0.0, 1.0]\n",
    "    for i = 3:n\n",
    "        push!(g, (g[end]+g[end-1])/2)\n",
    "    end\n",
    "    return g\n",
    "end\n",
    "gsequence(25)  # compute gₙ for n=0,1,…,24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)**  The easy way to see what will happen here is to realize that, when we expanded $x_n$ in terms of the eigenvectors, we got our constant term (which gave us $g_n \\to 2/3$) plus another term that went to zero like $(-1/2)^n$.   This second term accounts for the difference $g_n - 2/3$.   So, the difference decreases proportional to $(-1/2)^n$, i.e. $$\\boxed{\\frac{g_{n + 1} - 2/3}{g_n - 2/3} = -1/2} .$$\n",
    "\n",
    "We can also solve for this explicitly using our formula for $x_n$ in terms of the eigenvectors from the previous part.  The second row of $x_n$ is $g_n$, so we get\n",
    "$$\n",
    "g_n = \\frac{2}{3} - \\left( -\\frac{1}{2} \\right)^n  \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "We can easily check this using the Julia code (this was *not required*).   First, we can check explicitly that our formula for $g_n$ agrees with the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Array{Float64,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsequence(25) - 2/3 * (1 .- (-0.5) .^ (0:24))  # gₙ - (our formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, it gives our sequence exactly!\n",
    "\n",
    "We can also look at $g_n - 2/3$ and check that it is decreasing at the expected rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Array{Float64,1}:\n",
       " -0.666667   \n",
       "  0.333333   \n",
       " -0.166667   \n",
       "  0.0833333  \n",
       " -0.0416667  \n",
       "  0.0208333  \n",
       " -0.0104167  \n",
       "  0.00520833 \n",
       " -0.00260417 \n",
       "  0.00130208 \n",
       " -0.000651042\n",
       "  0.000325521\n",
       " -0.00016276 \n",
       "  8.13802e-5 \n",
       " -4.06901e-5 \n",
       "  2.03451e-5 \n",
       " -1.01725e-5 \n",
       "  5.08626e-6 \n",
       " -2.54313e-6 \n",
       "  1.27157e-6 \n",
       " -6.35783e-7 \n",
       "  3.17891e-7 \n",
       " -1.58946e-7 \n",
       "  7.94729e-8 \n",
       " -3.97364e-8 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = gsequence(25) .- 2/3  # compute gₙ - 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compute the ratios of subsequent terms, we get -0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24-element Array{Float64,1}:\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5\n",
       " -0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference[2:end] ./ difference[1:end-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (5+5+5+5 points)\n",
    "\n",
    "*(Although you are encouraged to use Julia to check your answers for this question, your solutions should explain your answers analytically.)*\n",
    "\n",
    "The following matrix $M$ is a Markov matrix (its columns sum to 1):\n",
    "$$\n",
    "M=\\begin{pmatrix}\n",
    "0.3 & 0.4 & 0.5\\\\\n",
    "0.3 & 0.4 & 0.3\\\\\n",
    "0.4 & 0.2 & 0.2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "and its steady-state eigenvector ($\\lambda=1$) is $s = \\begin{pmatrix}\n",
    "7/18\\\\\n",
    "1/3\\\\\n",
    "5/18\n",
    "\\end{pmatrix}$.  (Normalized so that the components of $s$ sum to 1.)\n",
    "\n",
    "**(a)** If we let $x = \\begin{pmatrix} 2 \\\\ 0 \\\\ 0 \\end{pmatrix}$, what vector does $M^n x$ approach as $n \\to \\infty$, and why?  (Give the correct magnitude and direction!)\n",
    "\n",
    "**(b)** For the same $x$, in what direction does $(M^T)^n x$ point as $n\\to\\infty$?  (You don't need to give the correct *magnitude*, just give a vector in the correct *direction*.)\n",
    "\n",
    "**(c)** Multiplying $M^T x$ does *not* preserve the *sum* of the components of $x$, but it does preserve *some* linear combination of the components.  i.e. there is some $v\\ne 0$ such that $v^T M^T x = v^T x$ for all $x$.  Give one such $v$.\n",
    "\n",
    "**(d)** Using your answer from (c), give a more exact answer to (b): give the *exact* vector (including magnitude) that $(M^T)^n x$ tends to as $n\\to \\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       "  2.77556e-17\n",
       "  1.38778e-17\n",
       " -2.77556e-17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [0.3 0.4 0.5\n",
    "     0.3 0.4 0.3\n",
    "     0.4 0.2 0.2]\n",
    "s = [7/18, 1/3, 5/18]\n",
    "\n",
    "# check steady state:\n",
    "(M - I) * s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "**(a)**  The Markov matrix $M$ has all positive entries, so its λ=1 eigenspace is 1-dimensional and must be spanned by the given steady-state vector $s$, and all other eigenvalues are smaller than 1 in absolute value.  In particular, from lecture, $M^nx$ will converge to a steady state solution as $n$ gets large,  i.e. it must point in the $\\boxed{\\text{direction of } s.}$  At the same time, we showed in class that multiplying by $M$ preserves the sum of the coordinates, so the sum of the coordinates of the limiting vector must be the same as the sum of coordinates of $x$, i.e. it must be 2.  The sum of the coordinates of $s$ was rigged to be 1, so $\\boxed{\\text{we see that the limiting state is } 2s.}$\n",
    "\n",
    "**(b)**  Recall that taking the transpose of a square matrix preserves the eigenvalues and their multiplicities.  So $M^T$ also has a 1-dimensional λ=1 eigenspace and all other eigenvalues have absolute value less than 1.  So for any vector $v$, $(M^T)^nv$ will converge to a vector in the λ=1 eigenspace.  So, we just need to work out which line this λ=1 eigenspace is, i.e. to find a λ=1 eigenvector.  But remember that for any Markov matrix $M$ its column sums are 1, so the row sums of $M^T$ are 1, and in particular the vector with all coordinates equal to 1 is an eigenvector of $M^T$ with eigenvalue 1.\n",
    "\n",
    "In fact, we did precisely this in the class and in the lecture notes.  We called $o$ the vector of all 1's, and showed that $o^T M = o^T$ is the statement that the **columns each sum to one**, or equivalently that $M^T o = o$ (o is a \"left eigenvector\" of M).   This is how we showed that $M$ had an eigenvalue of 1, because $M$ and $M^T$ have the same eigenvalues (same characteristic polynomial)!\n",
    "\n",
    "So $(M^T)^nx$ will point in the $\\boxed{\\text{direction of } o = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}}$ as $n$ gets large.\n",
    "\n",
    "**(c)**  To have that $v^TM^Tx = v^Tx$ for **all** $x$ is equivalent to having that $v^TM^T = v^T$ (why? – just plug in standard basis vectors for $x$ to see this), which is in turn equivalent (by taking transpose) to having that $Mv = v$, i.e. that $v$ is an eigenvector for $M$ with eigenvalue 1.  But we were given such an eigenvector: $\\boxed{\\text{the steady state solution } s.}$ (or **any nonzero multiple** of this vector $s$).\n",
    "\n",
    "**(d)**  From part (b), we know that $(M^T)^nx$ tends towards some vector in the span of $o = (1, 1, 1)$, i.e. some vector $(a, a, a)$ with equal coordinates.  From (c), the linear combination of coordinates $7x + 6y + 5z$ is preserved by multiplication by $M^T$, so we have to have $$14 = 7*2 + 6*0 + 5* 0 = 7 * a + 6 * a + 5 * a = 18a$$ which means that $a = 7/9$.  So $$\\boxed{\\lim_{n \\rightarrow \\infty} (M^T)^nx = \\begin{pmatrix}7/9 \\\\ 7/9 \\\\ 7/9\\end{pmatrix}.}$$\n",
    "\n",
    "This is all checked in the Julia code below.  First, let's check that we get $\\approx 2s$ for $M^{100} x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 1.33227e-15\n",
       " 1.22125e-15\n",
       " 9.99201e-16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [2,0,0]\n",
    "\n",
    "(M^100)*x - 2*s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's check that we get approximately (7/9, 7/9, 7/9) for $(M^T)^{100} x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 1.44329e-15\n",
       " 1.66533e-15\n",
       " 1.44329e-15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(M'^100)*x - [7/9,7/9,7/9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
